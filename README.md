# ğŸ§  å¤šè·³æ¨ç†åŒ»ç–—çŸ¥è¯†é—®ç­”ç³»ç»Ÿ

è¿™æ˜¯ä¸€ä¸ªåŸºäº **RAG (Retrieval-Augmented Generation)** æŠ€æœ¯çš„åŒ»ç–—çŸ¥è¯†é—®ç­”ç³»ç»Ÿï¼Œæ”¯æŒå¤šçŸ¥è¯†åº“ç®¡ç†ã€å¤šè½®å¯¹è¯å’Œåˆ›æ–°çš„å¤šè·³æ¨ç†åŠŸèƒ½ã€‚
ç³»ç»Ÿå¯ä»¥é€šè¿‡æœ¬åœ°çŸ¥è¯†åº“å’Œè”ç½‘æœç´¢è·å–ä¿¡æ¯ï¼Œä¸ºåŒ»ç–—å¥åº·ç›¸å…³é—®é¢˜æä¾›æ™ºèƒ½å›ç­”ã€‚

---

## 1. æ–‡ä»¶ç»“æ„

```
â”œâ”€â”€ rag.py              # ä¸»ç¨‹åºï¼ŒåŒ…å«RAGç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½å®ç°
â”œâ”€â”€ config.py           # é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«å„ç§å‚æ•°è®¾ç½®
â”œâ”€â”€ text2vec.py         # æ–‡æœ¬å‘é‡åŒ–å·¥å…·
â”œâ”€â”€ retrievor.py        # è”ç½‘æœç´¢å’Œæ–‡æœ¬æ£€ç´¢åŠŸèƒ½
â”œâ”€â”€ knowledge_bases/    # çŸ¥è¯†åº“æ ¹ç›®å½•
â”‚   â””â”€â”€ default/        # é»˜è®¤çŸ¥è¯†åº“
â”œâ”€â”€ output_files/       # ä¸´æ—¶è¾“å‡ºæ–‡ä»¶ç›®å½•
```

---

## 2. å®‰è£…ä¸éƒ¨ç½²

### ç¯å¢ƒè¦æ±‚

- Python 3.10+
- CUDA æ”¯æŒï¼ˆå¯é€‰ï¼Œç”¨äºGPUåŠ é€Ÿï¼‰

### ä¾èµ–åº“å®‰è£…

```bash
pip install -r requirements.txt
```

---

### 1. é…ç½® API å¯†é’¥

ç¼–è¾‘ `config.py` æ–‡ä»¶ï¼Œè®¾ç½®å¿…è¦çš„ API å¯†é’¥ï¼š

> é…ç½® API å¯†é’¥ï¼ˆæ–°ç”¨æˆ·å…è´¹èµ é€100ä¸‡tokenï¼‰  
> [https://bailian.console.aliyun.com/?spm=a2c4g.11186623.0.0.3c4a72a3Z9MBH1#/home](https://bailian.console.aliyun.com/?spm=a2c4g.11186623.0.0.3c4a72a3Z9MBH1#/home)

```python
# å‘é‡åŒ–APIé…ç½®ï¼ˆé˜¿é‡Œäº‘é€šä¹‰åƒé—®ï¼‰
api_key = "sk-ä½ çš„APIå¯†é’¥"
base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"

# LLM APIé…ç½®ï¼ˆé˜¿é‡Œäº‘é€šä¹‰åƒé—®ï¼‰
llm_api_key = "sk-ä½ çš„APIå¯†é’¥"
llm_base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
llm_model = "qwen-plus"
```

---

### 2. å¯åŠ¨ç³»ç»Ÿ

å¯åŠ¨åç³»ç»Ÿå°†åœ¨ä»¥ä¸‹åœ°å€è¿è¡Œï¼š

- æœ¬åœ°è®¿é—®: [http://localhost:7860](http://localhost:7860)  
- å…¬ç½‘è®¿é—®: å¯åŠ¨æ—¶ä¼šæ˜¾ç¤º share é“¾æ¥

---

## 3. ç³»ç»ŸåŠŸèƒ½

- **å¤šçŸ¥è¯†åº“ç®¡ç†**ï¼šåˆ›å»ºã€åˆ é™¤ã€æŸ¥çœ‹å¤šä¸ªçŸ¥è¯†åº“  
- **æ–‡ä»¶å¯¼å…¥**ï¼šæ”¯æŒä¸Šä¼  TXT å’Œ PDF æ–‡ä»¶åˆ°çŸ¥è¯†åº“  
- **è¯­ä¹‰æ£€ç´¢**ï¼šåŸºäºå‘é‡ç›¸ä¼¼åº¦çš„æ–‡æ¡£æ£€ç´¢  
- **å¤šè·³æ¨ç†**ï¼šåˆ›æ–°çš„å¤šè·³æ¨ç†æœºåˆ¶ï¼Œé€šè¿‡è¿­ä»£æ£€ç´¢å’Œæ¨ç†æ‰¾åˆ°æ›´å…¨é¢çš„ç­”æ¡ˆ  
- **è”ç½‘æœç´¢**ï¼šé›†æˆ web æœç´¢åŠŸèƒ½è¡¥å……çŸ¥è¯†åº“ä¿¡æ¯  
- **å¤šè½®å¯¹è¯**ï¼šæ”¯æŒåŸºäºå†å²ä¸Šä¸‹æ–‡çš„å¯¹è¯  
- **æµå¼å“åº”**ï¼šå®æ—¶æ˜¾ç¤ºæ£€ç´¢å’Œæ¨ç†è¿‡ç¨‹  
- **è¡¨æ ¼è¾“å‡º**ï¼šæ”¯æŒä»¥ Markdown è¡¨æ ¼è¾“å‡ºç»“æ„åŒ–ä¿¡æ¯  

---

## 4. æ ¸å¿ƒç®—æ³•

### 4.1 è¯­ä¹‰åˆ†å— (Semantic Chunking)

ç³»ç»Ÿä½¿ç”¨å¢å¼ºçš„å¥å­åˆ†å‰²å™¨å°†æ–‡æ¡£åˆ†æˆè¯­ä¹‰è¿è´¯çš„å—ï¼Œä¼˜åŒ–æ£€ç´¢æ•ˆæœï¼š

```python
def semantic_chunk(text: str, chunk_size=800, chunk_overlap=20) -> List[dict]:
    class EnhancedSentenceSplitter(SentenceSplitter):
        # å¢å¼ºçš„åˆ†å¥å™¨ï¼Œæ”¯æŒä¸­æ–‡æ ‡ç‚¹
        def __init__(self, *args, **kwargs):
            custom_seps = ["ï¼›", "!", "?", "\n"]
            separators = [kwargs.get("separator", "ã€‚")] + custom_seps
            kwargs["separator"] = '|'.join(map(re.escape, separators))
            super().__init__(*args, **kwargs)
```

---

### 4.2 å¤šè·³æ¨ç† RAG ç³»ç»Ÿ

å¤šè·³æ¨ç†æ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼Œå®ç°äº†è¿­ä»£å¼çš„æ£€ç´¢å’Œæ¨ç†è¿‡ç¨‹ï¼š

```bash
python rag.py
```

```python
class ReasoningRAG:
    """
    å¤šè·³æ¨ç†RAGç³»ç»Ÿï¼Œé€šè¿‡è¿­ä»£å¼çš„æ£€ç´¢å’Œæ¨ç†è¿‡ç¨‹å›ç­”é—®é¢˜ï¼Œæ”¯æŒæµå¼å“åº”
    """
```

---

### 4.3 å‘é‡åŒ–ä¸æ£€ç´¢

ç³»ç»Ÿä½¿ç”¨ **FAISS** è¿›è¡Œé«˜æ•ˆçš„å‘é‡æ£€ç´¢ï¼š

```python
def retrieve_and_answer(self, query: str, use_table_format: bool = False) -> Tuple[str, Dict[str, Any]]:
    """æ‰§è¡Œå¤šè·³æ£€ç´¢å’Œå›ç­”ç”Ÿæˆçš„ä¸»è¦æ–¹æ³•"""
    # åˆå§‹æ£€ç´¢
    query_vector = self._vectorize_query(query)
    initial_chunks = self._retrieve(query_vector, self.initial_candidates)
    
    # åˆå§‹æ¨ç†
    reasoning = self._generate_reasoning(query, initial_chunks, hop_number=0)
    
    # è¿­ä»£è·³æ•°è¿›è¡Œæ£€ç´¢å’Œæ¨ç†
    hop = 1
    while (hop < self.max_hops and 
           not reasoning["is_sufficient"] and 
           reasoning["follow_up_queries"]):
        
        for follow_up_query in reasoning["follow_up_queries"]:
            follow_up_vector = self._vectorize_query(follow_up_query)
            follow_up_chunks = self._retrieve(follow_up_vector, self.refined_candidates)
        
        reasoning = self._generate_reasoning(
            query, hop_chunks, previous_queries=all_queries[:-1], hop_number=hop
        )
        hop += 1
    
    answer = self._synthesize_answer(query, all_chunks, reasoning_steps, use_table_format)
```

---

## 5. API é›†æˆ

ç³»ç»Ÿæ”¯æŒé€šè¿‡ OpenAI å…¼å®¹æ¥å£è°ƒç”¨ç¬¬ä¸‰æ–¹åµŒå…¥ä¸ LLM æœåŠ¡ã€‚

```python
def vectorize_query(query, model_name=Config.model_name, batch_size=Config.batch_size) -> np.ndarray:
    """å‘é‡åŒ–æ–‡æœ¬æŸ¥è¯¢ï¼Œè¿”å›åµŒå…¥å‘é‡"""
    embedding_client = OpenAI(
        api_key=Config.api_key,
        base_url=Config.base_url
    )
    
    completion = embedding_client.embeddings.create(
        model=model_name,
        input=batch,
        dimensions=Config.dimensions,
        encoding_format="float"
    )
```

---

## 6. ä½¿ç”¨æŒ‡å—

### 6.1 çŸ¥è¯†åº“ç®¡ç†

1. **åˆ›å»ºçŸ¥è¯†åº“**
   - åœ¨ â€œçŸ¥è¯†åº“ç®¡ç†â€ æ ‡ç­¾é¡µè¾“å…¥çŸ¥è¯†åº“åç§°  
   - ç‚¹å‡» â€œåˆ›å»ºçŸ¥è¯†åº“â€ æŒ‰é’®  

2. **ä¸Šä¼ æ–‡ä»¶**
   - é€‰æ‹©è¦ä¸Šä¼ çš„ TXT æˆ– PDF æ–‡ä»¶  
   - ç‚¹å‡»ä¸Šä¼ æŒ‰é’®  
   - ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†æ–‡ä»¶å¹¶æ„å»ºç´¢å¼•  

---

### 6.2 æé—®æ–¹å¼

1. åˆ‡æ¢åˆ° â€œå¯¹è¯äº¤äº’â€ æ ‡ç­¾é¡µ  
2. é€‰æ‹©è¦ä½¿ç”¨çš„çŸ¥è¯†åº“  
3. é…ç½®å¯¹è¯è®¾ç½®ï¼š  
   - å¯ç”¨/ç¦ç”¨è”ç½‘æœç´¢  
   - å¯ç”¨/ç¦ç”¨è¡¨æ ¼æ ¼å¼è¾“å‡º  
   - å¯ç”¨/ç¦ç”¨å¤šè·³æ¨ç†  
4. è¾“å…¥é—®é¢˜å¹¶æäº¤  
5. æŸ¥çœ‹æ£€ç´¢è¿›å±•å’Œå›ç­”ç»“æœ  

---

## æ–‡æ¡£ç»“æ„ç´¢å¼•

1. æ–‡ä»¶ç»“æ„  
2. å®‰è£…ä¸éƒ¨ç½²  
   - ç¯å¢ƒè¦æ±‚  
   - ä¾èµ–åº“  
3. ç³»ç»ŸåŠŸèƒ½  
4. æ ¸å¿ƒç®—æ³•  
   - è¯­ä¹‰åˆ†å—  
   - å¤šè·³æ¨ç†RAGç³»ç»Ÿ  
   - å‘é‡åŒ–ä¸æ£€ç´¢  
5. APIé›†æˆ  
6. ä½¿ç”¨æŒ‡å—  
   - çŸ¥è¯†åº“ç®¡ç†  
   - æé—®æ–¹å¼  
